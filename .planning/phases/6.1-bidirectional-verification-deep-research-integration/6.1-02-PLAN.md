---
phase: 6.1-bidirectional-verification-deep-research-integration
plan: 02
type: execute
---

<objective>
Integrate bidirectional verification into root orchestrator and update backend for long-running Deep Research tasks.

Purpose: Replace Phase 6 external_signal agent with new external_signal_v2 ParallelAgent, update database schema for new finding types, and ensure processor handles extended execution times.

Output: Fully integrated bidirectional verification with Deep Research, ready for production use with proper async handling and finding storage.
</objective>

<execution_context>
@/Users/orkhan/.claude/get-shit-done/workflows/execute-phase.md
@/Users/orkhan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/6.1-bidirectional-verification-deep-research-integration/6.1-RESEARCH.md
@.planning/phases/6.1-bidirectional-verification-deep-research-integration/6.1-01-SUMMARY.md

## Integration Points
@backend/agents/orchestrator/agent.py
@backend/app/services/processor.py
@backend/requirements.txt

## New Sub-Agents (from Plan 1)
- InternetToReport agent (enhanced Phase 6)
- ReportToInternet agent (new bidirectional)
- DeepResearchClient wrapper

## Key Constraint
From RESEARCH.md:
- Deep Research takes 5-20 minutes per task
- Two parallel agents = $4-10 per audit
- Background task execution already in place (FastAPI BackgroundTasks)
- Need to handle claim verification findings in addition to signal findings
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ParallelAgent orchestrator for external_signal_v2</name>
  <files>
    backend/agents/orchestrator/sub_agents/external_signal_v2/__init__.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/agent.py
  </files>
  <action>
Create ParallelAgent that orchestrates internet_to_report and report_to_internet in parallel.

1. **agent.py**:
```python
"""External Signal V2 agent - bidirectional verification with Deep Research."""
from google.adk.agents import ParallelAgent
from .sub_agents.internet_to_report import internet_to_report_agent
from .sub_agents.report_to_internet import report_to_internet_agent

external_signal_v2_agent = ParallelAgent(
    name='external_signal_v2',
    description='Bidirectional verification using Deep Research for comprehensive external signal analysis',
    sub_agents=[
        internet_to_report_agent,    # Searches web for info contradicting report (Phase 6 enhanced)
        report_to_internet_agent,    # Verifies report claims against web (new bidirectional)
    ],
)
```

2. **__init__.py**:
```python
"""External Signal V2 agent with bidirectional Deep Research verification."""
from .agent import external_signal_v2_agent

__all__ = ['external_signal_v2_agent']
```

**What to avoid:**
- Don't use SequentialAgent - sub-agents are independent and should run in parallel
- Don't add output_schema to ParallelAgent - sub-agents handle their own outputs
- Don't add tools to ParallelAgent - it's purely orchestration

**Why:** ParallelAgent enables both sub-agents to run simultaneously, reducing total latency from potential 40 minutes (sequential) to 20 minutes (parallel, limited by slowest agent).
  </action>
  <verify>
python -c "from backend.agents.orchestrator.sub_agents.external_signal_v2 import external_signal_v2_agent; print(f'Orchestrator: {external_signal_v2_agent.name}, Sub-agents: {len(external_signal_v2_agent.sub_agents)}')"
  </verify>
  <done>ParallelAgent created with name external_signal_v2, includes both sub-agents, imports successfully, no circular dependencies</done>
</task>

<task type="auto">
  <name>Task 2: Update root orchestrator to use external_signal_v2</name>
  <files>backend/agents/orchestrator/agent.py, backend/agents/orchestrator/__init__.py</files>
  <action>
Replace Phase 6 external_signal agent with Phase 6.1 external_signal_v2 agent in root orchestrator.

1. **agent.py**: Update imports and sub_agents list
```python
"""Root orchestrator agent definition."""
from google.adk.agents import ParallelAgent
from .sub_agents import (
    numeric_validation_agent,
    logic_consistency_agent,
    disclosure_compliance_agent,
    external_signal_v2_agent,  # Phase 6.1: Bidirectional verification with Deep Research
)

root_agent = ParallelAgent(
    name='audit_orchestrator',
    description='Coordinates parallel validation agents for financial statement audit',
    sub_agents=[
        numeric_validation_agent,       # Phase 3: Numeric validation pipeline
        logic_consistency_agent,        # Phase 4: Logic consistency detection
        disclosure_compliance_agent,    # Phase 5: Disclosure compliance checking
        external_signal_v2_agent,       # Phase 6.1: Enhanced external signal with Deep Research
    ],
)
```

2. **sub_agents/__init__.py**: Update exports
```python
from .numeric_validation import numeric_validation_agent
from .logic_consistency import logic_consistency_agent
from .disclosure_compliance import disclosure_compliance_agent
from .external_signal_v2 import external_signal_v2_agent

__all__ = [
    'numeric_validation_agent',
    'logic_consistency_agent',
    'disclosure_compliance_agent',
    'external_signal_v2_agent',
]
```

**What to avoid:**
- Don't keep both external_signal and external_signal_v2 - replace completely
- Don't update processor.py in this task - that's Task 3

**Why:** Replaces Phase 6 single-direction verification with Phase 6.1 bidirectional verification while maintaining backward compatibility in processor (handled in next task).
  </action>
  <verify>
python -c "from backend.agents.orchestrator import root_agent; print(f'Root agent sub-agents: {[a.name for a in root_agent.sub_agents]}')"
  </verify>
  <done>Root orchestrator updated with external_signal_v2_agent, imports successfully, all 4 sub-agents present (numeric, logic, disclosure, external_signal_v2)</done>
</task>

<task type="auto">
  <name>Task 3: Update processor to handle new finding types from bidirectional verification</name>
  <files>backend/app/services/processor.py</files>
  <action>
Update DocumentProcessor.process_document() to extract findings from both internet_to_report and report_to_internet sub-agents.

Changes needed in extraction section (around line 76-79):

**Old extraction (Phase 6):**
```python
# 3d. Extract external signal findings
external_state = final_state.get("external_signal", {})
external_output = external_state.get("external_signal_output", {})
external_findings = external_output.get("findings", [])
```

**New extraction (Phase 6.1):**
```python
# 3d. Extract external signal findings (Phase 6.1: bidirectional)
# external_signal_v2 is ParallelAgent with two sub-agents
external_v2_state = final_state.get("external_signal_v2", {})

# 3d1. Extract internet→report findings (signals contradicting report)
internet_to_report_output = external_v2_state.get("internet_to_report_findings", {})
signal_findings = internet_to_report_output.get("findings", [])  # ExternalFinding list

# 3d2. Extract report→internet findings (claim verifications)
report_to_internet_output = external_v2_state.get("report_to_internet_findings", {})
verification_findings = report_to_internet_output.get("verifications", [])  # ClaimVerification list
```

Changes needed in saving section (around line 124-137):

**Old saving (Phase 6):**
```python
# 4d. Save external signal findings
for finding_data in external_findings:
    finding = FindingModel(
        job_id=job_id,
        category="external",
        severity="medium",
        description=finding_data.get("summary", ""),
        source_refs=[finding_data.get("source_url", "")],
        reasoning=f"Signal type: {finding_data.get('signal_type')}, ...",
        agent_id="external_signal",
    )
    self.db.add(finding)
```

**New saving (Phase 6.1):**
```python
# 4d. Save external signal findings (Phase 6.1: bidirectional)
# 4d1. Save internet→report signal findings
for finding_data in signal_findings:
    finding = FindingModel(
        job_id=job_id,
        category="external",
        severity="medium",
        description=finding_data.get("summary", ""),
        source_refs=[finding_data.get("source_url", "")],
        reasoning=f"Signal type: {finding_data.get('signal_type')}, "
                 f"Publication: {finding_data.get('publication_date', 'unknown')}, "
                 f"Potential contradiction: {finding_data.get('potential_contradiction', 'none')}",
        agent_id="external_signal_v2:internet_to_report",
    )
    self.db.add(finding)

# 4d2. Save report→internet verification findings
for finding_data in verification_findings:
    # Only save CONTRADICTED verifications as findings (VERIFIED is good news, CANNOT_VERIFY is neutral)
    if finding_data.get("status") != "CONTRADICTED":
        continue

    finding = FindingModel(
        job_id=job_id,
        category="external",
        severity="high",  # Contradicted claims are serious
        description=f"Claim verification failed: {finding_data.get('claim', '')}",
        source_refs=finding_data.get("source_urls", []),
        reasoning=f"Status: {finding_data.get('status')}, "
                 f"Evidence: {finding_data.get('evidence_summary', '')}, "
                 f"Discrepancy: {finding_data.get('discrepancy', 'none')}",
        agent_id="external_signal_v2:report_to_internet",
    )
    self.db.add(finding)
```

**What to avoid:**
- Don't delete Phase 6 code entirely - replace it cleanly with comments showing Phase 6.1 changes
- Don't save all verifications as findings - only CONTRADICTED status (VERIFIED is expected, CANNOT_VERIFY is neutral)
- Don't use same agent_id for both sub-agents - distinguish with :sub_agent_name suffix

**Why:** ParallelAgent structure means findings are now in two separate output_key locations (internet_to_report_findings, report_to_internet_findings) instead of one. Only contradicted verifications warrant findings - verified claims are normal, unverifiable claims are informational.
  </action>
  <verify>
python -c "from backend.app.services.processor import DocumentProcessor; print('Processor imports successfully')"
  </verify>
  <done>DocumentProcessor updated to extract from both sub-agents, saves signal findings and contradicted verification findings, distinguishes agent_ids with :sub_agent suffix, only saves CONTRADICTED verifications as findings</done>
</task>

<task type="auto">
  <name>Task 4: Add tenacity dependency for retry logic</name>
  <files>backend/requirements.txt</files>
  <action>
Add tenacity library to requirements.txt for Deep Research retry logic.

Append to requirements.txt:
```
tenacity>=8.0.0
```

**What to avoid:**
- Don't add version constraint too strict (>= not ==) - allows minor/patch updates
- Don't add to pyproject.toml if it doesn't exist - requirements.txt is current pattern

**Why:** DeepResearchClient uses tenacity decorators for exponential backoff retry logic on network failures. From RESEARCH.md standard stack.
  </action>
  <verify>
grep -q "tenacity" backend/requirements.txt && echo "tenacity added" || echo "ERROR: tenacity not found"
  </verify>
  <done>tenacity>=8.0.0 added to requirements.txt</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] ParallelAgent orchestrator imports successfully
- [ ] Root agent includes external_signal_v2 (not external_signal)
- [ ] Processor extracts from both internet_to_report_findings and report_to_internet_findings
- [ ] Processor only saves CONTRADICTED verifications as findings
- [ ] tenacity in requirements.txt
- [ ] No circular import dependencies
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- ParallelAgent orchestrator created for bidirectional verification
- Root orchestrator updated to use external_signal_v2
- Processor handles both signal findings and verification findings
- Only CONTRADICTED verifications saved as findings
- Dependencies updated (tenacity added)
- Phase 6.1 complete - ready for production testing
</success_criteria>

<output>
After completion, create `.planning/phases/6.1-bidirectional-verification-deep-research-integration/6.1-02-SUMMARY.md`:

# Phase 6.1 Plan 2: Integration and Backend Updates Summary

**Bidirectional verification integrated into root orchestrator with proper finding extraction**

## Accomplishments

- Created ParallelAgent orchestrator for external_signal_v2
- Updated root orchestrator to use external_signal_v2 (replaces Phase 6 agent)
- Updated processor to extract findings from both sub-agents
- Added logic to save only CONTRADICTED verifications as findings
- Added tenacity dependency for retry logic

## Files Created/Modified

- `backend/agents/orchestrator/sub_agents/external_signal_v2/agent.py` - ParallelAgent orchestrator
- `backend/agents/orchestrator/agent.py` - Root orchestrator updated
- `backend/app/services/processor.py` - Finding extraction updated for bidirectional pattern
- `backend/requirements.txt` - tenacity dependency added

## Decisions Made

- Only save CONTRADICTED verifications as findings - VERIFIED is expected, CANNOT_VERIFY is informational but not actionable
- Use agent_id suffix pattern (external_signal_v2:internet_to_report, external_signal_v2:report_to_internet) - distinguishes sub-agent sources
- CONTRADICTED verifications get severity="high" - more serious than external signals (medium)

## Issues Encountered

[Document any issues, or "None"]

## Next Phase Readiness

**Phase 6.1 complete.** Ready for testing:
- Deploy to staging
- Test with real financial statement
- Verify Deep Research async handling (20-minute execution)
- Validate findings extraction from both sub-agents
- Monitor cost ($4-10 per audit with 2 Deep Research calls)

**Note:** Phase 7 (Frontend Dashboard) already complete - may need UI updates to display new verification finding types if UX requires it.
</output>
