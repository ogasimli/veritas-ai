---
phase: 6.1-bidirectional-verification-deep-research-integration
plan: 01
type: execute
---

<objective>
Create Deep Research infrastructure and bidirectional verification sub-agents.

Purpose: Build the async wrapper for Gemini Deep Research API and implement two LlmAgent sub-agents (internet→report and report→internet) that use Deep Research for comprehensive external verification.

Output: Deep Research client with async polling, claim extraction prompts, and two sub-agents ready for ParallelAgent orchestration.
</objective>

<execution_context>
@/Users/orkhan/.claude/get-shit-done/workflows/execute-phase.md
@/Users/orkhan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/6.1-bidirectional-verification-deep-research-integration/6.1-RESEARCH.md

## Existing Architecture
@backend/agents/orchestrator/sub_agents/external_signal/agent.py
@backend/agents/orchestrator/sub_agents/external_signal/prompt.py
@backend/agents/orchestrator/sub_agents/external_signal/schema.py

## Key Research Findings
From RESEARCH.md:
- Deep Research uses Interactions API (not generate_content)
- Model name: `deep-research-pro-preview-12-2025`
- Requires `background=True` with async polling
- Costs $2-5 per task, takes 5-20 minutes
- Cannot embed directly in ADK - requires LlmAgent wrapper pattern
- 20-minute timeout recommended (API max is 60 min)

## Tech Stack
- google-genai SDK (Interactions API)
- google-adk (LlmAgent, ParallelAgent)
- tenacity library for retry logic
- Existing: gemini-3-flash-preview for coordination

## Established Patterns
From existing codebase:
- Sub-agents in `backend/agents/orchestrator/sub_agents/{name}/`
- Agent structure: `agent.py`, `prompt.py`, `schema.py`, `__init__.py`
- Sub-sub-agents in nested `sub_agents/` directory
- Pydantic schemas for structured outputs
- Session state output via `output_key`
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Deep Research async client wrapper</name>
  <files>backend/agents/orchestrator/sub_agents/external_signal_v2/deep_research_client.py</files>
  <action>
Create DeepResearchClient class with robust async polling for Gemini Deep Research API.

Implementation requirements:
1. Use `google.genai.Client()` for Interactions API access
2. Create `run_research(query, timeout_minutes=20)` method that:
   - Calls `client.interactions.create()` with `agent='deep-research-pro-preview-12-2025'`, `background=True`
   - Polls every 10 seconds using `client.interactions.get(interaction.id)`
   - Returns dict with: result (str), duration_seconds (float), status (completed/timeout/failed), error (optional)
   - Implements 20-minute default timeout (not API's 60-minute max)
3. Add retry logic with tenacity: `@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))`
4. Handle three exit conditions: completed (success), failed (API error), timeout (application limit)
5. Optional: `enable_thinking_summaries` parameter for streaming intermediate thoughts

**What to avoid:**
- Don't use generate_content API - Deep Research ONLY works with Interactions API
- Don't rely on 60-minute API timeout - always set application timeout (20 min recommended)
- Don't block FastAPI thread - this is synchronous wrapper for tool use, background task handles async at API level

**Why:** Deep Research requires async polling that takes 5-20 minutes. This wrapper provides a synchronous interface that ADK tools can invoke while handling Deep Research's long-running nature internally.
  </action>
  <verify>
python -c "from backend.agents.orchestrator.sub_agents.external_signal_v2.deep_research_client import DeepResearchClient; client = DeepResearchClient(); print('Client initialized successfully')"
  </verify>
  <done>DeepResearchClient class exists with run_research method, implements polling with 10-second intervals, handles timeout/completion/failure states, uses tenacity for retries</done>
</task>

<task type="auto">
  <name>Task 2: Create internet→report sub-agent (existing pattern enhanced)</name>
  <files>
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/__init__.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/internet_to_report/__init__.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/internet_to_report/agent.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/internet_to_report/prompt.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/internet_to_report/schema.py
  </files>
  <action>
Create InternetToReport sub-agent that enhances Phase 6 pattern with Deep Research.

1. **schema.py**: Use existing ExternalFinding schema from Phase 6, create InternetToReportOutput with findings list
2. **prompt.py**: Adapt Phase 6 INSTRUCTION prompt for Deep Research integration:
   - Extract company name and fiscal year from document
   - Instruct to use Deep Research tool for comprehensive multi-step research
   - Search types: news, litigation, financial distress (same as Phase 6)
   - Focus on reputable sources, reporting period timeframe
   - Output structured findings with signal_type, summary, source_url, publication_date, potential_contradiction

3. **agent.py**: Create LlmAgent with Deep Research tool integration:
```python
from google.adk.agents import LlmAgent
from google.adk.tools import Tool
from google.genai.types import GenerateContentConfig
from ...deep_research_client import DeepResearchClient

deep_research_client = DeepResearchClient()

def search_external_signals_tool(company_name: str, fiscal_year: str) -> str:
    """Tool that uses Deep Research to find external signals about company."""
    research_query = f"""
    Research external signals about {company_name} during fiscal year {fiscal_year}:

    Search for:
    1. News articles about major events, controversies, developments
    2. Litigation and legal proceedings
    3. Financial distress signals (credit downgrades, bankruptcy filings, liquidity concerns)

    Focus on reporting period {fiscal_year} and few months prior for context.
    Use only reputable sources (official filings, major news outlets, regulatory sites).

    For each signal found, provide:
    - Signal type (news/litigation/financial_distress)
    - Summary (2-3 sentences)
    - Source URL and publication date
    - Any potential contradictions with typical financial statement claims
    """

    result = deep_research_client.run_research(query=research_query, timeout_minutes=20)

    if result["status"] != "completed":
        return f"ERROR: Deep Research {result['status']} - {result['error']}"

    return result["result"]

internet_to_report_agent = LlmAgent(
    name="internet_to_report",
    model="gemini-3-flash-preview",  # Lightweight coordinator
    instruction=INSTRUCTION,
    tools=[Tool(search_external_signals_tool)],
    output_key="internet_to_report_findings",
    output_schema=InternetToReportOutput,
    generate_content_config=GenerateContentConfig(temperature=0.7),
)
```

**What to avoid:**
- Don't use Deep Research model name directly in LlmAgent - it's not a model, it's an agent accessed via Interactions API
- Don't skip error handling in tool - Deep Research can timeout or fail
- Don't use google_search tool - Deep Research already includes search capabilities internally

**Why:** This sub-agent enhances Phase 6's internet→report verification with Deep Research's multi-step reasoning and comprehensive research capabilities.
  </action>
  <verify>
python -c "from backend.agents.orchestrator.sub_agents.external_signal_v2.sub_agents.internet_to_report import internet_to_report_agent; print(f'Agent name: {internet_to_report_agent.name}')"
  </verify>
  <done>InternetToReport sub-agent created with Deep Research tool integration, uses gemini-3-flash-preview for coordination, implements search_external_signals_tool, outputs to internet_to_report_findings state key</done>
</task>

<task type="auto">
  <name>Task 3: Create report→internet sub-agent (new bidirectional pattern)</name>
  <files>
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/report_to_internet/__init__.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/report_to_internet/agent.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/report_to_internet/prompt.py,
    backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/report_to_internet/schema.py
  </files>
  <action>
Create ReportToInternet sub-agent for verifying report claims against internet sources.

1. **schema.py**: Create schemas for claim extraction and verification:
```python
from typing import List, Literal
from pydantic import BaseModel, Field

class VerifiableClaim(BaseModel):
    claim_text: str = Field(description="Exact quote from report")
    claim_type: Literal["date", "location", "partnership", "regulatory_filing", "award", "acquisition", "management"] = Field(
        description="Category of claim"
    )
    verification_query: str = Field(description="Search query to validate this claim")

class ClaimVerification(BaseModel):
    claim: str = Field(description="The claim being verified")
    status: Literal["VERIFIED", "CONTRADICTED", "CANNOT_VERIFY"] = Field(
        description="Verification result"
    )
    evidence_summary: str = Field(description="What was found online")
    source_urls: List[str] = Field(default_factory=list, description="Supporting URLs")
    discrepancy: str = Field(default="", description="Any discrepancies found")

class ReportToInternetOutput(BaseModel):
    verifications: List[ClaimVerification] = Field(
        default_factory=list,
        description="Verification results for extracted claims"
    )
```

2. **prompt.py**: Create two-stage prompt:
```python
INSTRUCTION = """You are verifying publicly verifiable claims from a financial statement.

## Stage 1: Extract Verifiable Claims

From the financial statement, identify publicly verifiable claims in these categories:
1. **Dates and timelines**: Fiscal year ends, transaction dates, incorporation dates
2. **Locations**: Registered addresses, office locations, jurisdictions
3. **Partnerships**: Named partners, suppliers, customers (if disclosed)
4. **Regulatory filings**: SEC filings, stock exchange listings, regulatory approvals
5. **Awards and certifications**: Industry awards, ISO certifications, accreditations
6. **Acquisitions**: Named transactions, amounts, dates
7. **Management**: Executive appointments, board members (if material)

For each claim, extract:
- Claim text (exact quote)
- Claim type (category above)
- Verification query (how to search for this)

## Stage 2: Verify Claims

Use the Deep Research tool to verify extracted claims. For each claim:
1. Search for authoritative sources (official registries, SEC filings, company websites)
2. Determine verification status: VERIFIED, CONTRADICTED, or CANNOT_VERIFY
3. Cite specific sources with URLs
4. Note any discrepancies (dates off, wording differences, etc.)

## Output

Structured verification results for each claim with status, evidence, and sources.
"""
```

3. **agent.py**: Create LlmAgent with Deep Research verification tool:
```python
def verify_claims_tool(claims_json: str) -> str:
    """Verify financial statement claims using Deep Research."""
    verification_prompt = f"""
    Verify these claims from a financial statement using publicly available information:

    {claims_json}

    For each claim:
    1. Search authoritative sources (registries, SEC filings, official sites)
    2. Determine: VERIFIED, CONTRADICTED, or CANNOT_VERIFY
    3. Cite sources with URLs
    4. Note discrepancies (dates off, wording differences)

    Format output as structured JSON with verification status for each claim.
    """

    result = deep_research_client.run_research(query=verification_prompt, timeout_minutes=20)

    if result["status"] != "completed":
        return f"ERROR: Deep Research {result['status']} - {result['error']}"

    return result["result"]

report_to_internet_agent = LlmAgent(
    name="report_to_internet",
    model="gemini-3-flash-preview",
    instruction=INSTRUCTION,
    tools=[Tool(verify_claims_tool)],
    output_key="report_to_internet_findings",
    output_schema=ReportToInternetOutput,
    generate_content_config=GenerateContentConfig(temperature=0.7),
)
```

**What to avoid:**
- Don't use regex for claim extraction - LLM understands semantic meaning better
- Don't verify all claims in one Deep Research call - extraction and verification are separate stages
- Don't skip CANNOT_VERIFY status - it's valid (not all claims are publicly verifiable)

**Why:** This sub-agent implements the new bidirectional verification pattern, extracting verifiable claims from the report and validating them against public sources using Deep Research.
  </action>
  <verify>
python -c "from backend.agents.orchestrator.sub_agents.external_signal_v2.sub_agents.report_to_internet import report_to_internet_agent; print(f'Agent name: {report_to_internet_agent.name}')"
  </verify>
  <done>ReportToInternet sub-agent created with claim extraction and Deep Research verification, uses verify_claims_tool, outputs to report_to_internet_findings state key, implements two-stage workflow (extract → verify)</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] DeepResearchClient class imports successfully
- [ ] Both sub-agents (internet_to_report, report_to_internet) import successfully
- [ ] Deep Research client has timeout protection (20 min default)
- [ ] Retry logic implemented with tenacity
- [ ] No imports of nonexistent modules or circular dependencies
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Deep Research client wrapper created with async polling
- InternetToReport sub-agent enhances Phase 6 pattern with Deep Research
- ReportToInternet sub-agent implements new bidirectional verification
- Both sub-agents use gemini-3-flash-preview for coordination, Deep Research for research
- Code follows existing agent structure patterns (agent.py, prompt.py, schema.py)
- No TypeScript/import errors
</success_criteria>

<output>
After completion, create `.planning/phases/6.1-bidirectional-verification-deep-research-integration/6.1-01-SUMMARY.md`:

# Phase 6.1 Plan 1: Deep Research Infrastructure Summary

**Deep Research async client and bidirectional sub-agents created**

## Accomplishments

- Created DeepResearchClient with async polling, timeout protection, retry logic
- Created InternetToReport sub-agent (enhanced Phase 6 pattern)
- Created ReportToInternet sub-agent (new bidirectional verification)
- Implemented tool wrappers for Deep Research integration

## Files Created/Modified

- `backend/agents/orchestrator/sub_agents/external_signal_v2/deep_research_client.py` - Async wrapper for Interactions API
- `backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/internet_to_report/` - Sub-agent 1
- `backend/agents/orchestrator/sub_agents/external_signal_v2/sub_agents/report_to_internet/` - Sub-agent 2
- Schema definitions for claims and verifications

## Decisions Made

- 20-minute timeout for Deep Research (vs 60-min API max) - faster failure feedback
- gemini-3-flash-preview for coordination, Deep Research for research - cost optimization
- Two-stage workflow for report→internet: extract claims, then verify - clearer separation

## Issues Encountered

[Document any issues, or "None"]

## Next Step

Ready for 6.1-02-PLAN.md - ParallelAgent orchestration and integration testing
</output>
