---
phase: 4.1-logic-reviewer
plan: 01
type: execute
---

<objective>
Refactor logic_consistency from single LlmAgent to 2-stage SequentialAgent (Detector → Reviewer) to filter false positives and assign business-impact severity levels.

Purpose: Reduce false positives in logic consistency findings (industry patterns, timing differences, context misunderstandings) and help auditors prioritize through High/Medium/Low severity assignment based on business impact.

Output: Enhanced logic_consistency agent with Detector (existing logic) and Reviewer (filtering + severity) sub-agents, maintaining backward compatibility with orchestrator integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/4.1-logic-reviewer/4.1-CONTEXT.md
@.planning/phases/04-logic-consistency/04-01-SUMMARY.md
@.planning/phases/03-numeric-validation/03-03-SUMMARY.md

**Key files:**
@backend/agents/orchestrator/sub_agents/logic_consistency/agent.py
@backend/agents/orchestrator/sub_agents/logic_consistency/schema.py
@backend/agents/orchestrator/sub_agents/logic_consistency/prompt.py
@backend/agents/orchestrator/sub_agents/numeric_validation/sub_agents/reviewer/schema.py

**Tech stack available:**
- Google ADK (LlmAgent, SequentialAgent patterns)
- Pydantic schemas for structured output
- Gemini 3 Pro

**Established patterns:**
- numeric_validation: 3-stage SequentialAgent (Extractor → FanOutVerifier → Reviewer)
- disclosure_compliance: 2-stage SequentialAgent (Scanner → FanOutVerifier)
- Sub-agent structure: agent.py, prompt.py, schema.py in sub_agents/{name}/

**Constraining decisions:**
- Phase 4: Used simple LlmAgent (now refactoring to SequentialAgent)
- All agents use gemini-3-pro-preview model
- Findings have category='logic' for DB differentiation

**From CONTEXT.md:**
- **Essential**: Balanced filtering (not too aggressive) + business-impact severity (High/Medium/Low)
- **Boundaries**: No new detection, no advice, no external research
- **Architecture**: Detector (current logic) → Reviewer (filter + severity)
- **False positives to catch**: Industry patterns, timing differences, lack of context
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor current agent into Detector sub-agent</name>
  <files>backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/agent.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/prompt.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/schema.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/__init__.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/__init__.py</files>
  <action>
Create sub_agents/detector/ directory structure mirroring numeric_validation pattern.

1. **Move existing logic to Detector**:
   - Copy current `prompt.py` INSTRUCTION to `sub_agents/detector/prompt.py` unchanged (this is the detection logic)
   - Copy current `schema.py` (LogicFinding, LogicConsistencyOutput) to `sub_agents/detector/schema.py`, renaming LogicConsistencyOutput → DetectorAgentOutput
   - Create `sub_agents/detector/agent.py`:
     ```python
     from google.adk.agents import LlmAgent
     from . import prompt
     from .schema import DetectorAgentOutput

     detector_agent = LlmAgent(
         name="LogicDetector",
         model="gemini-3-pro-preview",
         instruction=prompt.INSTRUCTION,
         output_key="detector_output",
         output_schema=DetectorAgentOutput,
     )
     ```
   - Create `sub_agents/detector/__init__.py`: `from .agent import detector_agent`

2. **Create sub_agents package**:
   - Create `sub_agents/__init__.py`: empty file for package structure

**CRITICAL**: Keep the existing detection prompt UNCHANGED - we're just moving it, not modifying behavior. The Detector should output the exact same findings as before.
  </action>
  <verify>
Directory structure exists:
- `backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/`
- Files: agent.py, prompt.py, schema.py, __init__.py
- Can import: `from backend.agents.orchestrator.sub_agents.logic_consistency.sub_agents.detector import detector_agent`
  </verify>
  <done>Detector sub-agent created with existing detection logic, directory structure follows numeric_validation pattern</done>
</task>

<task type="auto">
  <name>Task 2: Create Reviewer sub-agent for filtering and severity</name>
  <files>backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/agent.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/prompt.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/schema.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/__init__.py</files>
  <action>
Create Reviewer sub-agent that receives Detector findings and filters false positives + assigns severity.

1. **Schema** (`sub_agents/reviewer/schema.py`):
   ```python
   from typing import List
   from pydantic import BaseModel

   class RefinedFinding(BaseModel):
       fsli_name: str
       claim: str
       contradiction: str
       severity: str  # "high" | "medium" | "low"
       reasoning: str
       source_refs: List[str]

   class ReviewerAgentOutput(BaseModel):
       findings: List[RefinedFinding]
   ```

2. **Prompt** (`sub_agents/reviewer/prompt.py`):
   ```python
   INSTRUCTION = """You are a logic consistency reviewer. Your job is to filter false positives from potential logic inconsistencies and assign business-impact severity.

## Input

You receive potential logic findings from the Detector (from session state key "detector_output").

## Your Tasks

1. **Filter False Positives**: For each finding, determine if it's a real issue or false positive:

   **False Positive Patterns:**
   - **Industry-specific norms**: Common practices that seem odd without domain knowledge
     * SaaS deferred revenue > current revenue (normal for subscription businesses)
     * High R&D spend with no immediate products (biotech, deeptech are long-cycle)
     * Negative cash flow with revenue growth (growth-stage startups)

   - **Timing/seasonal effects**: Business cycles that look contradictory
     * Q4 revenue spike for retail (holiday season)
     * Agricultural company with seasonal inventory swings
     * Construction firms with weather-dependent cycles

   - **Context-dependent validity**: Statements logical with broader context
     * "Revenue down but margin up" (intentional strategic shift to higher-value products)
     * "Headcount down, costs up" (outsourcing transition increases vendor costs)
     * "Market share up in declining market" (competitors exited, you captured share)

   **If finding matches a false positive pattern**: REMOVE it (don't include in output)
   **If finding is genuinely illogical**: KEEP it and proceed to severity assignment

2. **Assign Business-Impact Severity** (for confirmed findings only):

   **High**: Material impact on financial position or going concern
   - Revenue recognition contradicts industry guidance (fraud risk)
   - Claims of profitability contradicted by cash burn rate
   - Going concern issues (insolvency risk not disclosed)
   - Core business contradictions affecting reliability

   **Medium**: Operational concerns or compliance risks
   - Significant operational inconsistencies requiring explanation
   - Regulatory compliance issues (not disclosed properly)
   - Material misstatements in non-core items

   **Low**: Minor oddities or disclosure quality issues
   - Unclear narratives that don't match numbers
   - Minor timing discrepancies
   - Immaterial inconsistencies

3. **Output Refined Findings**: For each confirmed finding:
   - Keep original fsli_name, claim, contradiction, reasoning, source_refs from Detector
   - Update severity based on business impact (may differ from Detector's severity)
   - Return only findings that passed false positive filter

## Key Principles

- **Balanced approach**: Filter obvious false positives but don't be overly aggressive
- **Business impact focus**: Severity reflects real-world consequences, not detection confidence
- **No new detection**: Only review Detector findings - don't look for new issues
- **No advice**: Report what's wrong, not how to fix it
- **Document-only context**: Use information from the financial statement only

## Example

**Detector finding (FALSE POSITIVE - REMOVE):**
- claim: "Revenue grew 200% while employee count fell 30%"
- contradiction: "Productivity gain seems impossible"
→ **Review**: This could be legitimate (automation, outsourcing, process improvement). Not inherently illogical. FILTER OUT.

**Detector finding (CONFIRMED - KEEP):**
- claim: "Company profitable per income statement but burning $5M/quarter in cash"
- contradiction: "Profitable companies generate cash, not consume it"
→ **Review**: This IS illogical without explanation (revenue recognition vs cash timing should be disclosed). KEEP.
→ **Severity**: HIGH (going concern risk if cash burn continues)
"""
   ```

3. **Agent** (`sub_agents/reviewer/agent.py`):
   ```python
   from google.adk.agents import LlmAgent
   from . import prompt
   from .schema import ReviewerAgentOutput

   reviewer_agent = LlmAgent(
       name="LogicReviewer",
       model="gemini-3-pro-preview",
       instruction=prompt.INSTRUCTION,
       output_key="reviewer_output",
       output_schema=ReviewerAgentOutput,
   )
   ```

4. **Package** (`sub_agents/reviewer/__init__.py`):
   ```python
   from .agent import reviewer_agent
   ```

**Key design**: Reviewer reads detector_output from session state (ADK pattern), filters false positives, assigns business-impact severity, outputs refined findings list.
  </action>
  <verify>
Directory structure exists:
- `backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/`
- Files: agent.py, prompt.py, schema.py, __init__.py
- Can import: `from backend.agents.orchestrator.sub_agents.logic_consistency.sub_agents.reviewer import reviewer_agent`
  </verify>
  <done>Reviewer sub-agent created with false-positive filtering and business-impact severity logic</done>
</task>

<task type="auto">
  <name>Task 3: Update root agent to SequentialAgent with Detector→Reviewer pipeline</name>
  <files>backend/agents/orchestrator/sub_agents/logic_consistency/agent.py, backend/agents/orchestrator/sub_agents/logic_consistency/schema.py, backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/__init__.py</files>
  <action>
Refactor root logic_consistency agent from single LlmAgent to SequentialAgent coordinating Detector→Reviewer.

1. **Update sub_agents package exports** (`sub_agents/__init__.py`):
   ```python
   from .detector import detector_agent
   from .reviewer import reviewer_agent

   __all__ = ["detector_agent", "reviewer_agent"]
   ```

2. **Update root schema** (`schema.py`):
   ```python
   from typing import List
   from pydantic import BaseModel

   # Import from reviewer (final output)
   from .sub_agents.reviewer.schema import RefinedFinding

   class LogicConsistencyOutput(BaseModel):
       """Output from logic consistency agent (after Detector→Reviewer pipeline)."""
       findings: List[RefinedFinding]
   ```

3. **Update root agent** (`agent.py`):
   ```python
   """Logic Consistency Agent - detects and refines semantic contradictions in financial statements."""
   from google.adk.agents import SequentialAgent

   from .sub_agents import detector_agent, reviewer_agent
   from .schema import LogicConsistencyOutput

   logic_consistency_agent = SequentialAgent(
       name="logic_consistency",
       sub_agents=[detector_agent, reviewer_agent],
       output_key="logic_consistency_output",
       output_schema=LogicConsistencyOutput,
   )
   ```

**CRITICAL**: The root agent now uses SequentialAgent (not LlmAgent). Output key "logic_consistency_output" and schema name LogicConsistencyOutput remain unchanged for backward compatibility with orchestrator and processor.py integration.

**Pipeline flow**:
1. Detector receives document text, outputs potential findings to detector_output
2. Reviewer reads detector_output, filters false positives, assigns severity, outputs refined findings to reviewer_output
3. SequentialAgent maps reviewer_output to logic_consistency_output (final output)
  </action>
  <verify>
- Root agent.py imports SequentialAgent, detector_agent, reviewer_agent
- Root agent.py instantiates SequentialAgent with sub_agents=[detector_agent, reviewer_agent]
- Root schema.py imports RefinedFinding from reviewer schema
- LogicConsistencyOutput.findings uses RefinedFinding type
- Can import: `from backend.agents.orchestrator.sub_agents.logic_consistency import logic_consistency_agent`
  </verify>
  <done>Root agent refactored to SequentialAgent coordinating Detector→Reviewer pipeline, maintains backward compatibility with orchestrator</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] Directory structure matches numeric_validation pattern (sub_agents/detector/, sub_agents/reviewer/)
- [ ] Detector contains original detection logic unchanged
- [ ] Reviewer implements false-positive filtering and business-impact severity
- [ ] Root agent uses SequentialAgent with 2 sub-agents
- [ ] Imports work: `from backend.agents.orchestrator.sub_agents.logic_consistency import logic_consistency_agent`
- [ ] No changes to orchestrator.py or processor.py needed (backward compatible)
</verification>

<success_criteria>

- All tasks completed
- logic_consistency refactored from LlmAgent → SequentialAgent (Detector → Reviewer)
- Detector sub-agent created with existing detection logic
- Reviewer sub-agent created with false-positive filtering + severity assignment
- Root agent maintains backward compatibility (same output_key, output_schema name)
- No errors in imports or agent instantiation
</success_criteria>

<output>
After completion, create `.planning/phases/4.1-logic-reviewer/4.1-01-SUMMARY.md`:

---
phase: 4.1-logic-reviewer
plan: 01
subsystem: agents
tags: [sequential-agent, gemini, orchestrator, refactoring, false-positive-filtering]

# Dependency graph
requires:
  - phase: 04-logic-consistency
    provides: Single LlmAgent for logic detection
  - phase: 03-numeric-validation
    provides: SequentialAgent pattern with Reviewer sub-agent
provides:
  - 2-stage logic_consistency pipeline (Detector → Reviewer)
  - False-positive filtering for industry patterns, timing differences, context issues
  - Business-impact severity assignment (High/Medium/Low)
affects: [orchestrator integration (backward compatible)]

# Tech tracking
tech-stack:
  added: []
  patterns: ["2-stage SequentialAgent pattern", "False-positive filtering with context awareness", "Business-impact severity logic"]

key-files:
  created:
    - backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/detector/
    - backend/agents/orchestrator/sub_agents/logic_consistency/sub_agents/reviewer/
  modified:
    - backend/agents/orchestrator/sub_agents/logic_consistency/agent.py
    - backend/agents/orchestrator/sub_agents/logic_consistency/schema.py

key-decisions:
  - "Refactored from LlmAgent to SequentialAgent (Detector→Reviewer)"
  - "Maintained backward compatibility (same output_key, schema name)"
  - "Focused Reviewer on filtering + severity only (no new detection, no advice)"

patterns-established:
  - "2-stage pipeline for non-map-reduce agents"
  - "False-positive filtering patterns for logic consistency (industry norms, timing, context)"
  - "Business-impact severity scale for findings prioritization"

issues-created: []

# Metrics
duration: TBD
completed: TBD
---

# Phase 4.1 Plan 01: Logic Reviewer Summary

**[Substantive one-liner describing what shipped]**

## Accomplishments

- [Key outcomes]

## Files Created/Modified

- [List files with descriptions]

## Decisions Made

- [Key decisions and rationale, or "None"]

## Issues Encountered

- [Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 4.1 complete. logic_consistency agent now has false-positive filtering and business-impact severity assignment.

**Current architecture:**
```
logic_consistency (SequentialAgent)
├── detector_agent - Identifies potential semantic contradictions
└── reviewer_agent - Filters false positives, assigns business-impact severity
```

Ready to proceed with Phase 5.1 (Disclosure Reviewer) or Phase 6 (External Signal).
</output>
